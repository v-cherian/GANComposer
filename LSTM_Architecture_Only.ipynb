{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM Architecture Only.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep4FnY9HVnKc"
      },
      "source": [
        "# LSTM #######################################################################\n",
        "def initialize_parameters():\n",
        "    parameters = {}\n",
        "    parameters['fgw'] = np.random.normal(0,0.01,(INPUT+HIDDEN,HIDDEN))\n",
        "    parameters['igw'] = np.random.normal(0,0.01,(INPUT+HIDDEN,HIDDEN))\n",
        "    parameters['ogw'] = np.random.normal(0,0.01,(INPUT+HIDDEN,HIDDEN))\n",
        "    parameters['ggw'] = np.random.normal(0,0.01,(INPUT+HIDDEN,HIDDEN))\n",
        "    parameters['how'] = np.random.normal(0,0.01,(HIDDEN,OUTPUT)) \n",
        "    return parameters\n",
        "\n",
        "\n",
        "def initialize_V(parameters):\n",
        "    V = {}\n",
        "    V['vfgw'] = np.zeros(parameters['fgw'].shape)\n",
        "    V['vigw'] = np.zeros(parameters['igw'].shape)\n",
        "    V['vogw'] = np.zeros(parameters['ogw'].shape)\n",
        "    V['vggw'] = np.zeros(parameters['ggw'].shape)\n",
        "    V['vhow'] = np.zeros(parameters['how'].shape)\n",
        "    return V\n",
        "\n",
        "\n",
        "def initialize_S(parameters):\n",
        "    S = {}\n",
        "    S['sfgw'] = np.zeros(parameters['fgw'].shape)\n",
        "    S['sigw'] = np.zeros(parameters['igw'].shape)\n",
        "    S['sogw'] = np.zeros(parameters['ogw'].shape)\n",
        "    S['sggw'] = np.zeros(parameters['ggw'].shape)\n",
        "    S['show'] = np.zeros(parameters['how'].shape)\n",
        "    return S\n",
        "\n",
        "\n",
        "def get_embeddings(batch_dataset, embeddings):\n",
        "    embedding_dataset = np.matmul(batch_dataset, embeddings)\n",
        "    return embedding_dataset\n",
        "\n",
        "\n",
        "def lstm_cell(batch_dataset, prev_activation_matrix, prev_cell_matrix, parameters):\n",
        "    concat_dataset = np.concatenate((batch_dataset, prev_activation_matrix), axis=1)\n",
        "    fa = sigmoid(np.matmul(concat_dataset, parameters['fgw']))\n",
        "    ia = sigmoid(np.matmul(concat_dataset, parameters['igw']))\n",
        "    oa = sigmoid(np.matmul(concat_dataset, parameters['ogw']))\n",
        "    ga = tanh(np.matmul(concat_dataset, parameters['ggw']))\n",
        "    cell_memory_matrix = np.multiply(fa, prev_cell_matrix) + np.multiply(ia, ga)\n",
        "    activation_matrix = np.multiply(oa, tanh(cell_memory_matrix))\n",
        "    lstm_activations = {}\n",
        "    lstm_activations['fa'] = fa\n",
        "    lstm_activations['ia'] = ia\n",
        "    lstm_activations['oa'] = oa\n",
        "    lstm_activations['ga'] = ga\n",
        "    return lstm_activations,cell_memory_matrix,activation_matrix\n",
        "\n",
        "\n",
        "def output_cell(activation_matrix, parameters):\n",
        "    output_matrix = softmax(np.matmul(activation_matrix, parameters['how'])) \n",
        "    return output_matrix\n",
        "\n",
        "\n",
        "def cal_loss_accuracy(batch_labels, output_cache):\n",
        "    loss, accuracy, prob = 0, 0, 1\n",
        "    batch_size = batch_labels[0].shape[0]\n",
        "    for i in range(1, len(output_cache)+1):\n",
        "        labels = batch_labels[i]\n",
        "        pred = output_cache['o' + str(i)]\n",
        "        prob = np.multiply(prob, np.sum(np.multiply(labels, pred), axis=1).reshape(-1, 1))\n",
        "        loss += np.sum((np.multiply(labels, np.log(pred)) + np.multiply(1-labels, np.log(1-pred))), axis=1).reshape(-1, 1)\n",
        "        accuracy += np.array(np.argmax(labels, 1) == np.argmax(pred, 1), dtype=np.float32).reshape(-1, 1)\n",
        "    perplexity = np.sum((1 / prob)**(1 / len(output_cache))) / batch_size\n",
        "    loss = np.sum(loss) * (-1 / batch_size)\n",
        "    accuracy = (np.sum(accuracy) / (batch_size)) / len(output_cache)\n",
        "    \n",
        "    return perplexity, loss, accuracy\n",
        "    \n",
        "\n",
        "def forward_propagation(batches, parameters, embeddings):\n",
        "    batch_size = batches[0].shape[0]\n",
        "    lstm_cache, activation_cache, cell_cache = {}, {}, {}\n",
        "    output_cache, embedding_cache = {}, {}\n",
        "    a0 = np.zeros([batch_size, HIDDEN], dtype=np.float32)\n",
        "    c0 = np.zeros([batch_size, HIDDEN], dtype=np.float32)\n",
        "    activation_cache['a0'] = a0\n",
        "    cell_cache['c0'] = c0\n",
        "    for i in range(len(batches) - 1):\n",
        "        batch_dataset = batches[i]\n",
        "        batch_dataset = get_embeddings(batch_dataset, embeddings)\n",
        "        embedding_cache['emb' + str(i)] = batch_dataset\n",
        "        lstm_activations, ct, at = lstm_cell(batch_dataset, a0, c0, parameters)\n",
        "        ot = output_cell(at, parameters)\n",
        "        lstm_cache['lstm' + str(i+1)]  = lstm_activations\n",
        "        activation_cache['a'+str(i+1)] = at\n",
        "        cell_cache['c' + str(i+1)] = ct\n",
        "        output_cache['o'+str(i+1)] = ot\n",
        "        a0 = at\n",
        "        c0 = ct  \n",
        "    return embedding_cache, lstm_cache, activation_cache, cell_cache, output_cache\n",
        "\n",
        "\n",
        "def calculate_output_cell_error(batch_labels, output_cache, parameters):\n",
        "    output_error_cache, activation_error_cache = {}, {}\n",
        "    for i in range(1, len(output_cache)+1):\n",
        "        error_output = output_cache['o' + str(i)] - batch_labels[i]\n",
        "        error_activation = np.matmul(error_output, parameters['how'].T)\n",
        "        output_error_cache['eo'+str(i)] = error_output\n",
        "        activation_error_cache['ea'+str(i)] = error_activation\n",
        "    return output_error_cache, activation_error_cache\n",
        "\n",
        "\n",
        "def calculate_single_lstm_cell_error(activation_output_error, next_activation_error,\n",
        "                                     next_cell_error, parameters, lstm_activation,\n",
        "                                     cell_activation, prev_cell_activation):\n",
        "    activation_error = activation_output_error + next_activation_error\n",
        "    oa = lstm_activation['oa']\n",
        "    ia = lstm_activation['ia']\n",
        "    ga = lstm_activation['ga']\n",
        "    fa = lstm_activation['fa']\n",
        "    eo = np.multiply(np.multiply(np.multiply(activation_error, tanh(cell_activation)), oa), 1-oa)\n",
        "    cell_error = np.multiply(np.multiply(activation_error, oa), dtanh(tanh(cell_activation)))\n",
        "    cell_error += next_cell_error\n",
        "    ei = np.multiply(np.multiply(np.multiply(cell_error, ga), ia), 1-ia)\n",
        "    eg = np.multiply(np.multiply(cell_error, ia), dtanh(ga))\n",
        "    ef = np.multiply(np.multiply(np.multiply(cell_error, prev_cell_activation), fa), 1-fa)\n",
        "    prev_cell_error = np.multiply(cell_error, fa)\n",
        "    embed_activation_error = np.matmul(ef, parameters['fgw'].T)\n",
        "    embed_activation_error += np.matmul(ei, parameters['igw'].T)\n",
        "    embed_activation_error += np.matmul(eo, parameters['ggw'].T)\n",
        "    embed_activation_error += np.matmul(eg, parameters['ogw'].T)\n",
        "    input_units = parameters['fgw'].shape[0] - parameters['fgw'].shape[1]\n",
        "    prev_activation_error = embed_activation_error[:, input_units:]\n",
        "    embed_error = embed_activation_error[:, :input_units]\n",
        "    lstm_error = {}\n",
        "    lstm_error['ef'] = ef\n",
        "    lstm_error['ei'] = ei\n",
        "    lstm_error['eo'] = eo\n",
        "    lstm_error['eg'] = eg\n",
        "    return prev_activation_error, prev_cell_error, embed_error, lstm_error\n",
        "\n",
        "\n",
        "def backward_propagation(batch_labels, embedding_cache, lstm_cache,\n",
        "                         activation_cache, cell_cache, output_cache, parameters):\n",
        "    output_error_cache, activation_error_cache = calculate_output_cell_error(batch_labels, output_cache, parameters)\n",
        "    lstm_error_cache, embedding_error_cache = {}, {}\n",
        "    eat = np.zeros(activation_error_cache['ea1'].shape)\n",
        "    ect = np.zeros(activation_error_cache['ea1'].shape)\n",
        "    for i in range(len(lstm_cache), 0, -1):\n",
        "        pae, pce, ee, le = calculate_single_lstm_cell_error(activation_error_cache['ea'+str(i)], eat, ect, parameters, lstm_cache['lstm'+str(i)], cell_cache['c'+str(i)], cell_cache['c'+str(i-1)])\n",
        "        lstm_error_cache['elstm'+str(i)] = le\n",
        "        embedding_error_cache['eemb'+str(i-1)] = ee\n",
        "        eat = pae\n",
        "        ect = pce\n",
        "    derivatives = {}\n",
        "    derivatives['dhow'] = calculate_output_cell_derivatives(output_error_cache, activation_cache, parameters)\n",
        "    lstm_derivatives = {}\n",
        "    for i in range(1, len(lstm_error_cache)+1):\n",
        "        lstm_derivatives['dlstm'+str(i)] = calculate_single_lstm_cell_derivatives(lstm_error_cache['elstm'+str(i)], embedding_cache['emb'+str(i-1)], activation_cache['a'+str(i-1)])\n",
        "    derivatives['dfgw'] = np.zeros(parameters['fgw'].shape)\n",
        "    derivatives['digw'] = np.zeros(parameters['igw'].shape)\n",
        "    derivatives['dogw'] = np.zeros(parameters['ogw'].shape)\n",
        "    derivatives['dggw'] = np.zeros(parameters['ggw'].shape)\n",
        "    for i in range(1, len(lstm_error_cache)+1):\n",
        "        derivatives['dfgw'] += lstm_derivatives['dlstm'+str(i)]['dfgw']\n",
        "        derivatives['digw'] += lstm_derivatives['dlstm'+str(i)]['digw']\n",
        "        derivatives['dogw'] += lstm_derivatives['dlstm'+str(i)]['dogw']\n",
        "        derivatives['dggw'] += lstm_derivatives['dlstm'+str(i)]['dggw']\n",
        "    return derivatives, embedding_error_cache\n",
        "\n",
        "\n",
        "def calculate_output_cell_derivatives(output_error_cache, activation_cache, parameters):\n",
        "    dhow = np.zeros(parameters['how'].shape)\n",
        "    batch_size = activation_cache['a1'].shape[0]\n",
        "    for i in range(1, len(output_error_cache)+1):\n",
        "        output_error = output_error_cache['eo' + str(i)]\n",
        "        activation = activation_cache['a'+str(i)]\n",
        "        dhow += np.matmul(activation.T,output_error)/batch_size\n",
        "    return dhow\n",
        "\n",
        "\n",
        "def calculate_single_lstm_cell_derivatives(lstm_error, embedding_matrix, activation_matrix):\n",
        "    concat_matrix = np.concatenate((embedding_matrix, activation_matrix), axis=1) \n",
        "    batch_size = embedding_matrix.shape[0]\n",
        "    derivatives = {}\n",
        "    derivatives['dfgw'] = np.matmul(concat_matrix.T, lstm_error['ef']) / batch_size\n",
        "    derivatives['digw'] = np.matmul(concat_matrix.T, lstm_error['ei']) / batch_size\n",
        "    derivatives['dogw'] = np.matmul(concat_matrix.T, lstm_error['eo']) / batch_size\n",
        "    derivatives['dggw'] = np.matmul(concat_matrix.T, lstm_error['eg']) / batch_size\n",
        "    return derivatives\n",
        "\n",
        "\n",
        "def update_parameters(parameters, derivatives, V, S):\n",
        "    vfgw = BETA1 * V['vfgw'] + (1 - BETA1) * derivatives['dfgw']\n",
        "    vigw = BETA1 * V['vigw'] + (1 - BETA1) * derivatives['digw']\n",
        "    vogw = BETA1 * V['vogw'] + (1 - BETA1) * derivatives['dogw']\n",
        "    vggw = BETA1 * V['vggw'] + (1 - BETA1) * derivatives['dggw']\n",
        "    vhow = BETA1 * V['vhow'] + (1 - BETA1) * derivatives['dhow']\n",
        "    sfgw = BETA2 * S['sfgw'] + (1 - BETA2) * derivatives['dfgw']**2\n",
        "    sigw = BETA2 *S['sigw'] + (1 - BETA2) * derivatives['digw']**2\n",
        "    sogw = BETA2 *S['sogw'] + (1 - BETA2) * derivatives['dogw']**2\n",
        "    sggw = BETA2 * S['sggw'] + (1 - BETA2) * derivatives['dggw']**2\n",
        "    show = BETA2 * S['show'] + (1 - BETA2) * derivatives['dhow']**2\n",
        "    parameters['fgw'] -= LEARNING_RATE * (vfgw / (np.sqrt(sfgw) + 1e-6))\n",
        "    parameters['igw'] -= LEARNING_RATE * (vigw / (np.sqrt(sigw) + 1e-6))\n",
        "    parameters['ogw'] -= LEARNING_RATE * (vogw / (np.sqrt(sogw) + 1e-6))\n",
        "    parameters['ggw'] -= LEARNING_RATE * (vggw / (np.sqrt(sggw) + 1e-6))\n",
        "    parameters['how'] -= LEARNING_RATE * (vhow / (np.sqrt(show) + 1e-6))\n",
        "    V['vfgw'], V['vigw'], V['vogw'], V['vggw'], V['vhow'] = vfgw, vigw, vogw, vggw, vhow\n",
        "    S['sfgw'], S['sigw'], S['sogw'], S['sggw'], S['show'] = sfgw, sigw, sogw, sggw, show\n",
        "    return parameters, V, S\n",
        "\n",
        "\n",
        "def update_embeddings(embeddings, embedding_error_cache, batch_labels):\n",
        "    embedding_derivatives = np.zeros(embeddings.shape)\n",
        "    batch_size = batch_labels[0].shape[0]\n",
        "    for i in range(len(embedding_error_cache)):\n",
        "        embedding_derivatives += np.matmul(batch_labels[i].T, embedding_error_cache['eemb'+str(i)]) / batch_size\n",
        "    embeddings = embeddings - LEARNING_RATE * embedding_derivatives\n",
        "    return embeddings"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}